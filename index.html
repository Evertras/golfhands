<!doctype html>
<html>

<head>
  <title>Golfhands</title>

</head>

<body>
  <style>
    video {
      display: none;
    }

    canvas {
      width: 90vw;
      height: 90vh;
      border: 2px solid black;
    }
  </style>
  <div>
    <video id="camera"></video>
  </div>

  <div>
    <canvas id="canvas" />
  </div>

  <button id="startBtn" disabled>
    Start
  </button>

  <button id="stopBtn">
    Stop
  </button>

  <div id="debug">
  </div>

  <script src="https://cdn.jsdelivr.net/npm/handtrackjs@latest/dist/handtrack.min.js"> </script>
  <script>
    const startBtn = document.getElementById("startBtn");
    const stopBtn = document.getElementById("stopBtn");
    const canvas = document.getElementById("canvas");
    const video = document.getElementById("camera");
    const debug = document.getElementById("debug")
    const mediaDevices = navigator.mediaDevices;
    const context = canvas.getContext('2d');
    let audioCtx = null;
    let osc;
    let vol;

    const modelParams = {
      flipHorizontal: true, // flip e.g for video
      maxNumBoxes: 5, // maximum number of boxes to detect
      iouThreshold: 0.3, // ioU threshold for non-max suppression
      scoreThreshold: 0.3, // confidence threshold for predictions.
    };

    let model = null;

    handTrack.load(modelParams).then((lmodel) => {
      model = lmodel;
      console.log(model);
      startBtn.disabled = false;
    });

    function runDetection() {
      model.detect(video).then((predictions) => {
        model.renderPredictions(predictions, canvas, context, video);

        const handPredictions = predictions.filter(p => p.label != "face");

        if (handPredictions.length > 0) {
          //console.log("Predictions: ", handPredictions);
          const box = handPredictions[0].bbox
          const xAverage = (box[0] + box[2]) / 2;

          // Funsies
          /*
          switch (handPredictions[0].label) {
            case "open":
              osc.type = "sine";
              break;

            case "closed":
              osc.type = "sawtooth";
              break;

            case "point":
              osc.type = "triangle";
              break;
          }
          */

          osc.frequency.value = xAverage;
        }

        requestAnimationFrame(runDetection);
      });
    }

    function startVideo() {
      handTrack.startVideo(video).then(status => {
        console.log(status);
        if (status) {
          runDetection();

          audioCtx = new (window.AudioContext || window.webkitAudioContext)();
          osc = audioCtx.createOscillator();
          vol = audioCtx.createGain();
          vol.gain.value = 0.1; // from 0 to 1, 1 full volume, 0 is muted
          osc.type = "sine";
          osc.frequency.value = 440;
          osc.connect(vol); // connect osc to vol
          vol.connect(audioCtx.destination); // connect vol to audioCtx destination
          osc.start(); // start it three seconds from now
        }
      });
    }

    document.addEventListener("DOMContentLoaded", () => {
      startBtn.addEventListener("click", () => {
        startVideo();
      });

      stopBtn.addEventListener("click", () => {
        handTrack.stopVideo(video);
      });
    });
  </script>
</body>

</html>
